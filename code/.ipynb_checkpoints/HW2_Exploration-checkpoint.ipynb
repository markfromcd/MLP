{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65e32efb-34fd-47c4-8614-b75587650151",
   "metadata": {},
   "source": [
    "# CS1470/2470 HW2: Exploring Your Model\n",
    "\n",
    "### Testing Out Your Model!\n",
    "\n",
    "Pull in your model into the notebook, test it out using the model that you settle on, and compare it against a keras implementation of your choice! Hypothesize why your implementation may be different. \n",
    "\n",
    "#### **Submit as PDF with your final submission!**\n",
    "\n",
    "**Requirements:**\n",
    "- Select a model of choice. Can definitely be a single-layer model.\n",
    "- A brief discussion of your dataset, including links to source, motivation, and preprocessing.\n",
    "    - This can be pretty brief, since we already discuss MNIST at length. \n",
    "    - Feel free to try it on CIFAR, though this is optional!\n",
    "    - Feel free to reuse code from HW1!\n",
    "- Brief evaluation of your model. \n",
    "- Comparison against a keras model of similar implementation. \n",
    "    - *Feel free to use a model of your choice like in 2470 version, but you definitely don't need to do a multi-layered model.*\n",
    "\n",
    "### **[2470]** Explore Your Own Dataset!\n",
    "\n",
    "**Same requirements as above, but:**\n",
    "\n",
    "- You have to pick a different dataset; not MNIST or CIFAR-10. \n",
    "- A brief discussion of your dataset, including links to source, motivation, and preprocessing.\n",
    "- A network architecture motivated by your specific problem. \n",
    "    - **MUST BE MULTI-LAYERED!**\n",
    "    - Discuss motivation for your design choices and hurdles you may have had to overcome. \n",
    "- Brief evaluation of your model. \n",
    "    - Include a few possible options with evaluations to motivate your final selection of model and hyperparameters. \n",
    "    - Include a few qualitative motivations or ablation studies, such as a per-class performance breakdown, visualizations, or similar. \n",
    "- Comparison against a keras model of similar implementation.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7c565a",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cfe1e7",
   "metadata": {},
   "source": [
    "**YOUR DISCUSSION HERE!**\n",
    "\n",
    "- [**1470**] Feel free to change up the code, but this is probably the easiest way to go about this.\n",
    "- [**2470**] Modify accordingly. Feel free to make more cell blocks as well!\n",
    "\n",
    "*Feel free to clear out this markdown cell block and override with your actual discussion.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8e3da0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Shapes: (60000, 784) (60000,)\n",
      "Testing  Shapes: (10000, 784) (10000,)\n"
     ]
    }
   ],
   "source": [
    "## 1470: Feel free to change, but this is probably the easiest way to go about this.\n",
    "## 2470: Modify accordingly. Feel free to make more cell blocks as well\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport Beras, assignment, preprocess\n",
    "\n",
    "data_path = \"../data\"\n",
    "\n",
    "## Import MNIST train and test examples into train and testing data\n",
    "import preprocess\n",
    "X0, Y0 = preprocess.get_data_MNIST('train', data_path)\n",
    "X1, Y1 = preprocess.get_data_MNIST('test',  data_path)\n",
    "\n",
    "print(\"Training Shapes:\", X0.shape, Y0.shape)\n",
    "print(\"Testing  Shapes:\", X1.shape, Y1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115a5f94",
   "metadata": {},
   "source": [
    "## My Beras Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7f2026",
   "metadata": {},
   "source": [
    "**YOUR DISCUSSION HERE!**\n",
    "\n",
    "- [**1470**] Feel free to change up the code, but this is probably the easiest way to go about this.\n",
    "- [**2470**] Modify accordingly. Feel free to make more cell blocks as well!\n",
    "\n",
    "*Feel free to clear out this markdown cell block and override with your actual discussion.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09ba9a70",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (layers.py, line 35)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m~/opt/miniconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3398\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[0;36m  Input \u001b[0;32mIn [2]\u001b[0;36m in \u001b[0;35m<cell line: 12>\u001b[0;36m\u001b[0m\n\u001b[0;31m    from Beras.layers import Dense\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m~/GitHub/Brown-Deep-Learning/hw2-mlp-markfromcd/hw2/code/Beras/layers.py:35\u001b[0;36m\u001b[0m\n\u001b[0;31m    igrads =\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from Beras.onehot import OneHotEncoder\n",
    "from visualize import visualize_images, visualize_metrics\n",
    "from assignment import SequentialModel\n",
    "import numpy as np\n",
    "\n",
    "## Read in MNIST data, use the OneHotEncoder class to one hot encode the labels,\n",
    "## instantiate and compile your model, and train your model\n",
    "ohe = OneHotEncoder()\n",
    "ohe.fit(np.concatenate([Y0, Y1], axis=-1))\n",
    "\n",
    "from Beras.activations import Softmax\n",
    "from Beras.layers import Dense\n",
    "from Beras.losses import MeanSquaredError\n",
    "from Beras.metrics import CategoricalAccuracy\n",
    "from Beras.optimizers import BasicOptimizer\n",
    "\n",
    "model = SequentialModel([Dense(784, 10), Softmax()])\n",
    "model.compile(\n",
    "    optimizer=BasicOptimizer(0.02),\n",
    "    loss_fn=MeanSquaredError(),\n",
    "    acc_fn=CategoricalAccuracy(),\n",
    ")\n",
    "\n",
    "train_agg_metrics = model.fit(\n",
    "    X0, ohe(Y0), epochs=10, batch_size=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4e7c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualize import visualize_images, visualize_metrics\n",
    "\n",
    "visualize_metrics(train_agg_metrics[\"loss\"], train_agg_metrics[\"acc\"])\n",
    "visualize_images(model, X0, ohe(Y0))\n",
    "test_agg_metrics = model.evaluate(X1, ohe(Y1), batch_size=100)\n",
    "test_agg_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854a5de9",
   "metadata": {},
   "source": [
    "## Keras Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84aa4dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "532e45d8",
   "metadata": {},
   "source": [
    "## Model Analysis\n",
    "\n",
    "**[Required only for 2470; Feel free to delete section otherwise]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a2dda0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f904fcb",
   "metadata": {},
   "source": [
    "## Discussions\n",
    "\n",
    "Final thoughts? This can be whatever :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "759be6693a164ddeab1e231298c2a01a8302a7c7dfd4e560844dbce42a896f34"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
